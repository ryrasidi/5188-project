{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579f8543-d178-49bb-abfc-dcf7745cd0c6",
   "metadata": {},
   "source": [
    "## Step 1: Load the master clause file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd18d6f7-c346-4cb1-824d-a82b53f5a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load master_clauses file\n",
    "import pandas as pd\n",
    "master_clauses = pd.read_csv(\"CUAD_v1/master_clauses.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3506c6d3-88fd-41bf-90f3-22202e9976ae",
   "metadata": {},
   "source": [
    "## Step 2: Load CUAD full documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ec42c5-4d2a-41f1-8176-7719d833c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set paths\n",
    "label_folder = \"CUAD_v1/label_group_xlsx\"\n",
    "all_dfs = []\n",
    "\n",
    "# Loop through all Excel label files\n",
    "for file in os.listdir(label_folder):\n",
    "    if file.endswith(\".xlsx\"):\n",
    "        path = os.path.join(label_folder, file)\n",
    "        df = pd.read_excel(path)\n",
    "        df = df.melt(id_vars=[\"Filename\"], var_name=\"Clause_Type\", value_name=\"Clause_Text\")\n",
    "        df = df.dropna(subset=[\"Clause_Text\"])\n",
    "        all_dfs.append(df)\n",
    "\n",
    "# Combine all clauses\n",
    "df_long_all = pd.concat(all_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9228df81-3313-415b-b983-ec261ad3b1bc",
   "metadata": {},
   "source": [
    "## PHASE 1 - Clause Classification System\n",
    "Goal: Evaluate BERT & legal-specific models for classifying clauses into 41 CUAD clause types.\n",
    "\n",
    "## Step 1.1 - Prepare Training Data\n",
    "You need labeled clause examples. Then, encode the 41 clause types so that it is ready for training text classification models e.g. BERT, LegalBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8032a17f-9ce0-4481-b906-d9d14d72509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique clause types: 47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepare for encoding\n",
    "df_clauses = df_long_all[[\"Clause_Text\", \"Clause_Type\"]].rename(\n",
    "    columns={\"Clause_Text\": \"text\", \"Clause_Type\": \"label\"}\n",
    ")\n",
    "\n",
    "# Encode the clause type labels (e.g. Change of Control -> 0, Anti-assignment -> 1, etc.)\n",
    "le = LabelEncoder()\n",
    "df_clauses[\"label_encoded\"] = le.fit_transform(df_clauses[\"label\"])\n",
    "\n",
    "print(\"Number of unique clause types:\", len(le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab906aa9-ae7c-4406-94ff-1fbb149f9064",
   "metadata": {},
   "source": [
    "## Step 1.2 - Train Models\n",
    "Let's start with:\n",
    "1. Split your data\n",
    "2. Train a BERT model using Hugging Face's `transformers` and `datasets`\n",
    "3. Evaluate it\n",
    "4. Repeat with LegalBERT (a legal-domain-pretrained version of BERT)\n",
    "\n",
    "Train and compare:\n",
    "- BERT-base\n",
    "- LegalBERT\n",
    "- Any other specialized model...\n",
    "Use Hugging Face `Trainer` or `transformers` + `sklearn` pipeline.\n",
    "\n",
    "## Prepare datasets for model training\n",
    "Here's a setup using Hugging Face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2a85123-e9e9-4a50-a2a2-4b2fb4c6b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Keep only text and label_encoded\n",
    "df_clauses_model = df_clauses[[\"text\", \"label_encoded\"]].copy()\n",
    "\n",
    "# Force 'text' column to be string type\n",
    "df_clauses_model[\"text\"] = df_clauses_model[\"text\"].astype(str)\n",
    "\n",
    "# Split into train/test sets\n",
    "train_df, test_df = train_test_split(df_clauses_model, \n",
    "                                     test_size=0.2, \n",
    "                                     stratify=df_clauses_model[\"label_encoded\"], \n",
    "                                     random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce83a3dc-0856-4421-9755-1604ad0845c5",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Here's what we'll do next:\n",
    "1. Load a tokenizer (e.g. BERT's tokenizer).\n",
    "2. Apply the tokenizer to your datasets.\n",
    "3. Format the output for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1727ef2-7efb-4243-bb54-ee9c57072756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryhana Rasidi\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d968399ae4f4a68a7cd84b702ccfad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6902 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f10c09571f4c3e8e0c1ef4d1ece2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1726 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the tokenizer from a pre-trained model like bert-base-uncased\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the datasets: Define a function to tokenize the text and apply it\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format to PyTorch\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label_encoded\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label_encoded\"])\n",
    "\n",
    "# Rename label column to 'labels'\n",
    "train_dataset = train_dataset.rename_column(\"label_encoded\", \"labels\")\n",
    "test_dataset = test_dataset.rename_column(\"label_encoded\", \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c89a46-f5f4-43dd-9501-165d7fd0cb40",
   "metadata": {},
   "source": [
    "## Fine-tune BERT base model\n",
    "We'll use `trainer` API from Hugging Face's `transformers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "478b2e9a-f820-4f16-882c-543f0facdac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryhana Rasidi\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Load BERT base model\n",
    "num_labels = len(le.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "# Metric function\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da36ee-0195-482a-8897-7bdced7094b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='2589' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  11/2589 07:48 < 37:15:04, 0.02 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class PrintCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        print(f\"Step {state.global_step}: {logs}\")\n",
    "\n",
    "# Instantiate the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[PrintCallback()],\n",
    ")\n",
    "\n",
    "print('Training start...')\n",
    "trainer.train()\n",
    "print('Training done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0429c216-e262-461b-86b2-0fa49e22fe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3daa1f5e1c6143d785e2f9f79c1a2eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.37.2\n"
     ]
    }
   ],
   "source": [
    "#from transformers import TrainingArguments\n",
    "#help(TrainingArguments)\n",
    "#print(TrainingArguments.__module__)\n",
    "\n",
    "#args_test = TrainingArguments(output_dir=\"./test\")\n",
    "#print(args_test.output_dir)\n",
    "\n",
    "import transformers\n",
    "print(transformers.__version__)\n",
    "#print(transformers.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3901da-77fb-4896-9f4a-42c30e9137cd",
   "metadata": {},
   "source": [
    "## Step 1.3 - Evaluate\n",
    "Evaluate using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ae66b-7125-4f20-83f9-3508749f359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#print(classification_report(y_true, y_pred, target_names = le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5758f9d-3ccf-47de-8180-ebbcb41c688d",
   "metadata": {},
   "source": [
    "You can compare macro-F1, precision, recall per clause type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5d4b7-af7e-48ac-9c4e-20ac48415a72",
   "metadata": {},
   "source": [
    "## PHASE 2 - Clause Risk Assessment\n",
    "Goal: Predict severity or risk level of clauses\n",
    "\n",
    "## Step 2.1 - Define Risk Labels\n",
    "If your dataset doesn't already have risk labels, you must create them.\n",
    "Options:\n",
    "- Use heuristic rules e.g. clauses with \"terminate\", \"waive\", \"without consent\" = high risk)\n",
    "- Or manually annotate a subset (High, Medium, Low)\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f59e7d-7a1b-4480-bc98-64ffacf3a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_risk_heuristic(text):\n",
    "    if any(word in text.lower() for word in [\"terminate\", \"penalty\", \"waive\", \"without consent\"]):\n",
    "        return \"High\"\n",
    "    elif any(word in text.lower() for word in [\"notice\", \"require\", \"may\", \"prior\"]):\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "df_clauses[\"risk_level\"] = df_clauses[\"text\"].apply(simple_risk_heuristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a946817a-b7d9-4e62-b253-e818d478e615",
   "metadata": {},
   "source": [
    "You can refine this over time using patterns or ML models.\n",
    "\n",
    "## Step 2.2 - Train Secondary Model\n",
    "\n",
    "Train another classifier to predict `risk_level` from clause text. Again, use BERT or LegalBERT.\n",
    "Input: Clause Text\n",
    "Target: Risk level (High, Medium, Low)\n",
    "\n",
    "## PHASE 3 - Visual Risk Mapping\n",
    "Goal: Create visualizations like risk heatmaps / color-coded contract sections\n",
    "\n",
    "## Step 3.1 - Highlight Clauses in Full Text\n",
    "For each contract file:\n",
    "- Highlight or color-code clause segments in context\n",
    "\n",
    "Use libraries like:\n",
    "- spaCy + displacy for basic HTML highlighting\n",
    "- Plotly / Dash for heatmaps or interactive views\n",
    "- Streamlit if build a UI tool\n",
    "\n",
    "You could create a dictionary like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fdd7b0-19e9-4937-aaaf-53f6b6b697bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "{ \"clause_text\": \"X\", \"risk\": \"High\", \"color\": \"red\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724085b4-8165-43ee-8b91-2f5cd9f9285b",
   "metadata": {},
   "source": [
    "Then, render full text with color-coded spans.\n",
    "\n",
    "## Step 3.2 - Risk Heatmaps\n",
    "If you divide contracts into sections (e.g. every 500 tokens), you can visualize clause density per section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf4855-582f-45b4-bc29-b331ea151d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dummy example\n",
    "risk_scores = [0.2, 0.7, 0.9, 0.4, 0.1]\n",
    "sns.heatmap([risk_scores], cmap=\"Reds\", xticklabels=[\"Sec1\", \"Sec2\", \"Sec3\", \"Sec4\", \"Sec5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8503899-44b7-4549-9ecb-320e2e20777d",
   "metadata": {},
   "source": [
    "## PHASE 4 - Explainability\n",
    "Goal: Explain why a clause is flagged as risky or belonging to a class.\n",
    "\n",
    "## Step 4.1 - Use Explainability Tools\n",
    "Start with:\n",
    "- LIME (Local Interpretable Model Explanations)\n",
    "- SHAP (SHapley Additive Explanations)\n",
    "- Attention Visualization for transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba199bc-cf06-4cfe-a8bd-7bdaa36abed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: LIME\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=le.classes_)\n",
    "explanation = explainer.explain_instance(text_instance, model.predict_proba)\n",
    "explanation.show_in_notebook()\n",
    "\n",
    "# Example: SHAP\n",
    "import shap\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer([\"clause text here\"])\n",
    "shap.plots.text(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfc20fd-59f1-46f9-aa24-884329637b14",
   "metadata": {},
   "source": [
    "Attention:\n",
    "Use Hugging Face's `bertviz` or extract `attention weights` for heatmaps of token importance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
